Authors:
Thomas Francis <toj320@gmail.com>

======================================================
7/13/2021

Welcome to the technical documentation of project Semblance.

Table of Contents

Introduction
DevOps
    Setting Up
        General Idea for Feedback Loop
        Version Control - Git
        Docker
        Tasks for Docker
Backend
    Introduction
    Building the Core
    Features to Build and How to Build Them
        Algorithm for returning search results data
        Returning randomly returning text-based adventures
        Setting email Verification, possibly with Sendgrid
        Security
Frontend
    Introduction
        Build Components
    Building the Core
    Features to Build and How to Build Them
        Archetype Settings
        Proximity Settings
        Results Box
        ChatApp Box

======================================================
Introduction
======================================================

PLEASE READ THIS

Everyone needs to read the DevOps section. Frontend and Backend are optional to your specialization.

======================================================
DevOps - Setting Up
======================================================

------------------------------------------------------
General Idea for Feedback Loop
------------------------------------------------------

The feedback loop is being able to see your changes on the intended device.

Apparently, you can use the Chrome DevTools Device Simulation

Right-click > Inspect > upper-left corner, click on toggle device to change the viewport for mobile.

Google's mobile-friendly test tool
https://search.google.com/test/mobile-friendly

It's possible to use Android Studio to set up a phone simulation but that's up to you.
Phone simulation uses a ton of processing power and is therefore slow to start, even for high-end computers.

------------------------------------------------------
Version Control - Git
------------------------------------------------------

https://www.robinwieruch.de/git-team-workflow

There are two main branches: staging and main.
There are many smaller feature branches.
These smaller feature branches will always merge with the staging branch.
Features include small changes and bug fixes.
It is only when a product is ready to be released, that the staging branch will merge with the main branch.

main (The final release or the actual product)
staging (the most updated version of the application)
features (temporary, meant to be merged with staging)

1. Either create a new feature branch or check out an available branch

    git checkout -b <branch_name>
        When you're creating a new feature branch, please prefix it with "feat-". For example,
            feat-<your_feature_branch_name>
            feat-my_feet
            feat-technical-docs

    git checkout <branch_name>

    "git fetch" stuff below

        If you want to see the progress of a feature, but don't want to deal with the merge conflicts, use "git fetch".
        https://www.atlassian.com/git/tutorials/syncing/git-fetch
        git fetch is used for code review since it is isolated from local development work.
        If you want on this new branch, you'll need to pull the latest changes with:
        git pull --rebase origin <branch_name>
        This puts your commits on top of the remote branch's commits.
            If there is a merge conflict, resolve then:
                git add .
                    git rebase --continue
                    Or worst case scenario if nothing works
                    git rebase abort


2. Do work on the branch. If you want to start over from scratch, simply delete the feature branch locally.
    Local deletion - to free memory on your machine
    git branch -d <branch_name>
    Remote Deletion - only if whatever you wrote will never be useful
    git push origin -d <branch_name>

3. What we already know:
    git add .
    git commit -m "<commit_message>"
    git push origin <branch_name>

    tip: "git add -u" can be used to move all changed files to the staging branch, excluding new files.

4. Repeat step 3 until you're ready to merge the feature with the staging branching.

5. When you're completed with a feature, submit a pull request (PR) to merge your feature into the staging branch:
    git checkout staging
    git pull origin staging
    git merge --no-ff <branch_name>
        --no-ff means "no fast-forward".
        Fast-forwarding occurs when instead of a merge commit, git just moves the branch pointer to the incoming commit.
        This usually occurs when performing a git pull without any local changes.
        https://stackoverflow.com/questions/9069061/what-is-the-difference-between-git-merge-and-git-merge-no-ff
    git push origin staging


Situation:
Someone merged their feature branch to the staging branch and
I'd like to keep my feature branch updated with the new staging branch.
Solution:
git checkout <your_feature_branch>
git rebase staging
    This merges all your changes from your feature branch on top of the staging branch.
git push origin <your_feature_branch>
    If pushing does not work, use the force. The force push, that is:
    git push -f origin <branch_name>
    Other people's pushes on the same would get overwritten if you did not pull them.


------------------------------------------------------
Docker
------------------------------------------------------

TL:DR;

Use "docker-compose up -d" to run the container.
Use "docker-compose exec [image_name] [your installation command]" whenever you need to install a new package/module.
For example:
    docker-compose exec backend sudo pipenv install ipython
Use "docker-compose down" when you want to destroy your container such as when you install a new package OR
when you're done for the day
Use "docker-compose up -d --build" after you install a new package so it exists in your container.


Brief Introduction to Docker

https://www.youtube.com/watch?v=Gjnup-PuquQ

Install Docker

    Apple Silicon
    https://docs.docker.com/docker-for-mac/apple-silicon/

    Windows (works for Home version now. It used to be that only Windows Pro version worked.)
    https://docs.docker.com/docker-for-windows/install/
    https://www.docker.com/blog/docker-desktop-for-windows-home-is-here/

General Docker Steps

1. Pull or create a Docker image. Usually you'll want to pull an existing image:
https://hub.docker.com/search?q=&type=image&image_filter=official

2. Once you have an image, theoretically, you could use a docker run command to run that image.

    Template:
        docker run --name=[image_name] -d [base image]:[tag of the version]
    Example:
        For running a mysql server:
        docker run --name=yorha -d mysql/mysql-server:latest

3. "Dockerfile" and "docker-compose.yml" files. Think of them as the "Makefiles" of docker
    
    a. The "Dockerfile" (no extension) is a collection "docker image" commands that are used to build the image.

    b. The "docker-compose.yml" file is a collection of "docker run" commands that are used to run images in containers.

    There might be multiple Dockerfiles, such as one for the backend and one for the frontend.
    But there only ever needs to be one docker-compose.yml file to run both of these images.

    When the Dockerfile and docker-compose.yml files are present,
    you can use the "docker-compose up -d" command to build the images and run these images in separate containers.

    flag

    -d          means to run this container detached. Detached as in,
                so the container will run on its on terminal and not from the one you're currently using.
    --build     means to rebuild the image. You must rebuild the image after installing new packages to maintain changes.
                You can install new packages with the "docker-compose exec [image_name] [command to install package]" command.


    To shutdown your containers, such as whenever you want to rebuild your images, run:

    docker-compose down

    All data stored on these images will be lost.
    Therefore, in order to save your data across images,
    you must save it locally on your machine by defining a volume location in the docker-compose.yml file.

    For example:

services:
  volumes:
    postgres_data:
  db:
    image: postgis/postgis
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=taliyah
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    
    Under volumes, the name of the host source container is postgres_data.
    Under db, volumes appears again to define the data storage destination for the container.
    This will be where the data will be stored on your local machine.
    ###### If you're using windows, you'll obviously want to change this storage path. ######

    We need a volume within the db service and a volume outside of the db service so that
    this data is available to multiple services. For example, what if we wanted a container
    to backup the data of the volume.

------------------------------------------------------
Tasks for Docker
------------------------------------------------------

- pull the python docker image
    https://hub.docker.com/_/python/

- pull the node.js docker image
    https://hub.docker.com/_/node

- pull postgis/postgis
    https://registry.hub.docker.com/r/postgis/postgis

- define your volume location in the docker-compose.yml file. This can be anywhere... reasonable.

======================================================
Backend
======================================================

------------------------------------------------------
Introduction
------------------------------------------------------

Please read DevOps before reading this section.

The following steps are in order using the plus/minus format.
"-" means that this task is incomplete
"+" means that this task is complete
"#" means that this line is a tip on how to complete the task

The steps in the next section will be used to build the Backend core.
Building the core means having something that generally works and can have features added to it later.

------------------------------------------------------
Building the Core
------------------------------------------------------

Realistically, you could copy and paste the Django settings from the original Semblance repo if you're stuck or need help.
https://github.com/tieje/Semblance

- create the docker-compose.yml file in the project-level directory
    - copy and paste the parts of the docker-compose.yml file that you think you'll need.
        # You don't need everything right now.

- set up virtual python environment with pipenv
    - pip3 install pipenv
    - cd backend
    - pipenv --python 3.8.5 install django==3.1.6
        # this was the latest release of django at the time
    - pipenv shell
        # this command enters the virtual environment.
        # you can confirm by checking the version of python that you're using.

- set up normal working django default page
    - pipenv shell
    - django-admin startproject config .
    - python manage.py runserver

- add postgresql database
    - overwrite the database settings in django settings.py
    - install psycopg2-binary from the docker command line
        # docker-compose exec [options] [-e KEY=VAL...] SERVICE COMMAND [ARGS...]
        - sudo docker-compose exec backend pipenv install psycopg2-binary==2.8.5
        - sudo docker-compose exec backend sh
            # I'm actually not sure what this does...
        - docker-compose down
        - docker-compose up -d --build
        - docker-compose exec backend python manage.py migrate
        - docker-compose exec backend python manage.py createsuperuser
        - site admin check
            http://127.0.0.1:8000/admin

- get geodjango working
    https://docs.djangoproject.com/en/3.1/ref/contrib/gis/install/
    https://stackoverflow.com/questions/60403731/geodjango-and-postgis-setup-in-docker
    - installed special libraries needed for Geodjango
        - binutils
        - libproj-dev
        - gdal-bin
        - python-gdal
        - python3-gdal
        # for your convenience:
        docker-compose exec backend pipenv install binutils libproj-dev gdal-bin python-gdal python3-gdal
    - rebuild the image
        - docker-compose down
        - docker-compose up -d --build

- intall graphene on django
    https://docs.graphene-python.org/projects/django/en/latest/
    - docker-compose exec backend pipenv install graphene-django
    - add graphene-django to installed apps in settings
        https://github.com/graphql-python/graphene-django/
    - rebuild image
        - docker-compose down
        - docker-compose up -d --build

- create django MVP accounts app
    - docker-compose exec backend python manage.py startapp accounts
    - create MVP models
        - extend custom users model to include location with geodjango
        # only location is added to the custom user model for now. Characters will be added later.
    - install accounts app to settings
    - register model in admin.py file
    - update AUTH_USER_MODEL so that the CustomUser model is used instead of the User model
    - sudo docker-compose exec backend python manage.py makemigrations accounts
        - next replace the engine of the database:
            # https://stackoverflow.com/questions/12538510/getting-databaseoperations-object-has-no-attribute-geo-db-type-error-when-do
        - create the superuser again:
            docker-compose exec backend python manage.py createsuperuser
    - sudo docker-compose exec backend python manage.py migrate
    - test login and check postgis data
    - Add an example user with django admin

- set up the rest_framework
    # referring to the django rest framework book, chapter 3 and beyond
    - docker-compose exec backend pipenv install djangorestframework
    - add 'rest_framework' to installed apps on settings
    - insert REST_FRAMEWORK in settings and define default permissions
        - think about implementing 'rest_framework.permissions.IsAuthenticated'
            # 'rest_framework.permissions.IsAuthenticated'
            # makes it so that only authenticated users can edit information on the API
        - define 'DEFAULT_AUTHENTICATION_CLASSES' pg. 108
            - 'rest_framework.authentication.TokenAuthentication'
                # refer to pg 106 for security improvements for JWTs
            - add 'rest_framework.authtoken' to installed apps
                # I'll do this at the very end to decrease the amount of hard migrations
    - add account's API url to config folder's urls.py file
    - create an app-level serializers.py file
        - edit the serializers.py file such that it can handle geojson output
        - docker-compose exec backend pipenv install djangorestframework-gis
        - add 'rest_framework_gis' to installed apps
    +-update views.py file to create a generic view for looking at data
        +-create generic view and comment this out to use as a backup
        - create viewset for AccountsDetail and AccountsList class
    - update accounts' app-level urls.py file
        - create routers for viewsets
    - use CORS to require specific HTTP Headers for http requests
        - docker-compose exec backend pipenv install django-cors-headers
        - add 'corsheaders' to installed apps in settings
        - add 'corsheaders.middleware.CorsMiddleware' to MIDDLEWARE
        - define CORS_ORIGIN_WHITELIST in settings
            # we define ports 3000 and 8000 because that is what we'll be using for react and django respectively
    - create basic login, logout, and authentication endpoints:
        - docker-compose exec backend pipenv install dj-rest-auth
        - add 'dj_rest_auth' to installed apps
        - configure urls.py file in config folder for dj-rest-auth pg. 112
    - set up user-registration
        - docker-compose exec backend pipenv install django-allauth
        - check pg 117 for additions to Installed apps in settings
        - define EMAIL_BACKEND in settings
        - define SITE_ID in settings
        - set up registration urls in config/urls.pyk
    - docker-compose exec backend python manage.py migrate
    - rebuild image

- set up graphQL
    - docker-compose exec backend pipenv install graphene-django
    - add to installed apps:
        https://docs.graphene-python.org/projects/django/en/latest/installation/
    - docker-compose exec backend pipenv install graphene_gis
    - add to installed apps:
        https://github.com/EverWinter23/graphene-gis
    - set up a graphQL url endpoint
    - define GRAPHENE in settings
    - docker-compose exec backend pipenv install graphene
    - docker-compose exec backend pipenv install django-graphiql
    - set up graphQL schema in project-level directory
        https://docs.graphene-python.org/projects/django/en/latest/installation/
        https://docs.graphene-python.org/projects/django/en/latest/tutorial-plain/
    - determine how to ensure that geojson objects are used by graphql

- Implement schema and documentation for REST API
    - docker-compose exec backend pipenv install pyyaml
    - docker-compose exec backend pipenv install uritemplate
    - docker-compose exec backend pipenv install drf-yasg
    - docker-compose down
        - docker-compose up -d --build
    - docker-compose exec backend python manage.py generateschema > openapi-schema.yml
    - add to installed_apps in settings
    - set up URLs

If you would like to go into the actual container and check out the file structure, use the following commands:

- test image and dockerfiles
    - cd Backend
    - sudo docker build -t backend:1 .
    - sudo docker run -it --name semblance -p 8000:8000 backend:1 bash

------------------------------------------------------
Features to Build and How to Build Them
------------------------------------------------------

======================================================
Frontend
======================================================

------------------------------------------------------
Introduction
------------------------------------------------------

Please read DevOps before reading this section.

The following steps are in order using the plus/minus format.
"-" means that this task is incomplete
"+" means that this task is complete
"#" means that this line is a tip on how to complete the task

The steps in the next section will be used to build the Backend core.
Building the core means having something that generally works and can have features added to it later.

------------------------------------------------------
Building the Core
------------------------------------------------------

+ install node.js on your computer
    https://nodejs.org/en/

+ cd frontend

+ install typescript on the docker container
    docker-compose exec frontend npm install -g typescript

+ npx create-react-app frontend --template typescript
https://create-react-app.dev/docs/adding-typescript/

+ test with yarn start
    yarn start
    + end the run Ctrl + C

+ replace the project-level docker-compose.yml file with the docker-compose.yml in the Docker-Compose_file folder

+ install Apollo on the docker container to generate a package-lock.json file
    npm install @apollo/client graphql

+ run containers and check if it works
    docker-compose up -d --build

+ test by going to http://localhost:3000/

+ install styled components
   npm install styled-components@^5.2.1 @types/styled-components@^5.1.9

+ rebuild image
    docker-compose down
    docker-compose up -d --build

------------------------------------------------------
Features to Build and How to Build Them
------------------------------------------------------

7/16/2021
TODO:
- build frontend component features in English for TypeScript
- start with proximity and gender settings component

